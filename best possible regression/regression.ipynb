{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/umap_test/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3155: DtypeWarning: Columns (118,123) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "/usr/local/anaconda3/envs/umap_test/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3155: DtypeWarning: Columns (121) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "/usr/local/anaconda3/envs/umap_test/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3155: DtypeWarning: Columns (88,107,116,117,121,123) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df2 = pd.read_csv('df2.csv')\n",
    "df3 = pd.read_csv('df3.csv')\n",
    "df4 = pd.read_csv('df4.csv')\n",
    "df5 = pd.read_csv('df5.csv')\n",
    "df6 = pd.read_csv('df6.csv')\n",
    "df7 = pd.read_csv('df7.csv')\n",
    "df8 = pd.read_csv('df8.csv')\n",
    "df9 = pd.read_csv('df9.csv')\n",
    "df10 = pd.read_csv('df10.csv')\n",
    "df11 = pd.read_csv('df11.csv')\n",
    "\n",
    "\n",
    "# remove columns if they miss in one of the dataframes\n",
    "data = pd.concat([df2, df3, df4, df5, df6, df7, df8, df9, df10, df11])\n",
    "# data.drop(columns = set(df.columns) ^ set(df1.columns), inplace=True)\n",
    "data = data[data['price']<60000]\n",
    "data = data[data['price']>1000]\n",
    "\n",
    "\n",
    "# modify date column to store length of time period since particular offer has been created\n",
    "def remove_polish_lang_from_date(date_val):\n",
    "    months =  {\n",
    "        'stycznia': '1', 'lutego': '2', 'marca': '3',\n",
    "        'kwietnia': '4', 'maja': '5', 'czerwca': '6',\n",
    "        'lipca': '7', 'sierpnia': '8', 'września': '9',\n",
    "        'października': '10', 'listopada': '11', 'grudnia': '12'\n",
    "    }\n",
    "    date_val = re.sub(r'^.*?,', '', date_val)\n",
    "    for k, v in months.items():\n",
    "        date_val = date_val.replace(k, v)\n",
    "    return date_val\n",
    "\n",
    "data['offer date'] = data['offer date'].apply(remove_polish_lang_from_date)\n",
    "data['offer date'] =  (datetime.datetime.now() - pd.to_datetime(data['offer date'], format=' %d %m %Y')).dt.days\n",
    "\n",
    "\n",
    "# merge generation along with car model to avoid name conflicts\n",
    "data['Wersja'] += ' ' + data['Marka pojazdu']\n",
    "data['Model pojazdu'] += ' ' + data['Generacja']\n",
    "\n",
    "data.drop(columns=['Generacja'], inplace=True)\n",
    "\n",
    "important_columns = {'offer date', 'Marka pojazdu', 'Model pojazdu', 'Rok produkcji', 'Przebieg',\n",
    "                     'Pojemność skokowa', 'Rodzaj paliwa', 'Napęd', 'Typ', 'Skrzynia biegów',\n",
    "                     'Bezwypadkowy', 'Liczba drzwi', 'Alufelgi', 'Wersja', 'Dach panoramiczny',\n",
    "                     'Kierownica po prawej (Anglik)', 'Moc', 'price'}\n",
    "\n",
    "data = data[important_columns]\n",
    "data.drop_duplicates(inplace=True)\n",
    "\n",
    "data['Kierownica po prawej (Anglik)'].fillna('Nie', inplace=True)\n",
    "data['Napęd'].fillna('Na przednie koła', inplace=True)\n",
    "data['Bezwypadkowy'].fillna('Tak', inplace=True)\n",
    "data['Liczba drzwi'].fillna(4, inplace=True)\n",
    "data['Alufelgi'].fillna(False, inplace=True)\n",
    "data['Dach panoramiczny'].fillna(False, inplace=True)\n",
    "\n",
    "data.dropna(subset=important_columns, inplace=True)\n",
    "\n",
    "data['Przebieg'] = data['Przebieg'].str.replace(' km', '').str.replace(' ', '')\n",
    "data['Pojemność skokowa'] = data['Pojemność skokowa'].str.replace(' cm3', '').str.replace(' ', '')\n",
    "data['Moc'] = data['Moc'].str.replace(' KM', '').str.replace(' ', '')\n",
    "for col in ['Rok produkcji', 'Przebieg', 'Pojemność skokowa', 'Moc', 'Liczba drzwi']:\n",
    "    data[col] = pd.to_numeric(data[col])\n",
    "\n",
    "numeric_columns = []\n",
    "numeric_columns.extend(list(data.dtypes[data.dtypes == np.int64].index))\n",
    "numeric_columns.extend(list(data.dtypes[data.dtypes == np.float64].index))\n",
    "numeric_columns = set(numeric_columns) & important_columns\n",
    "non_numeric_columns = important_columns - numeric_columns\n",
    "\n",
    "numeric_data = data[numeric_columns]\n",
    "non_numeric_data = data[non_numeric_columns]\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "oh_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "X = non_numeric_data.copy()\n",
    "y = numeric_data['price']\n",
    "out = oh_encoder.fit_transform(X, y)\n",
    "non_numeric_data = DataFrame(out, columns=oh_encoder.get_feature_names())\n",
    "full_data = pd.merge(numeric_data, non_numeric_data, left_index=True, right_index=True)\n",
    "\n",
    "############\n",
    "# lista = []\n",
    "# with open('lista.txt', 'r') as f:\n",
    "#     for item in full_data.columns:\n",
    "#         lista.append(f.readline())\n",
    "#\n",
    "# with open('lista2.txt', 'w') as f:\n",
    "#     for item in set(lista) - set(full_data.columns):\n",
    "#         f.write(f'{item}')\n",
    "# full_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression, BayesianRidge, ElasticNet, SGDRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, BaggingRegressor, GradientBoostingRegressor, AdaBoostRegressor, ExtraTreesRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "from sklearn.manifold import TSNE\n",
    "import umap\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "full_data = full_data.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "temp_X = full_data.drop(columns=['price'])\n",
    "y = full_data['price']\n",
    "\n",
    "reduced_datas = {}\n",
    "temp_X = StandardScaler().fit_transform(temp_X)\n",
    "#################\n",
    "\n",
    "# PCA\n",
    "reduced_datas['pca']= DataFrame(data=PCA(n_components=20).fit_transform(temp_X))\n",
    "# UMAP\n",
    "reduced_datas['umap']= DataFrame(data=umap.UMAP(n_components=20).fit_transform(temp_X))\n",
    "# SVD\n",
    "reduced_datas['svd']= DataFrame(data=TruncatedSVD(n_components=20).fit_transform(temp_X))\n",
    "# T-SNE\n",
    "reduced_datas['tsne']= DataFrame(data=TSNE(n_components=2).fit_transform(temp_X))\n",
    "################"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for reducer_name, X in reduced_datas.items():\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    fig, axes = plt.subplots(1, 2)\n",
    "    for i, model in enumerate([\n",
    "                  # MLPRegressor(max_iter=10,learning_rate_init=0.001, hidden_layer_sizes=(100, 500, 200)),\n",
    "                  LinearRegression(),\n",
    "                  # BayesianRidge(),\n",
    "                  # ElasticNet(),\n",
    "                  # GradientBoostingRegressor(),\n",
    "                  # ExtraTreesRegressor(),\n",
    "                  # RandomForestRegressor(),\n",
    "                  # BaggingRegressor(),\n",
    "                  # AdaBoostRegressor()\n",
    "                  ]):\n",
    "        model.fit(X_train, y_train)\n",
    "        print(f'{reducer_name} {model} MAE mean (cv=2) ={cross_val_score(model, X_test, y_test, scoring=\"neg_mean_absolute_error\", cv=2).mean()}')\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        fig.suptitle(f'Data after {reducer_name}')\n",
    "        axes[0].scatter(y_test, y_pred)\n",
    "        axes[0].set_title(f'{model}')\n",
    "        axes[0].set(xlabel='real price', ylabel='predicted price', xlim=0, ylim=0)\n",
    "\n",
    "        axes.flat[1].scatter(X[0], X[1])\n",
    "        axes.flat[1].set_title('features dependency')\n",
    "        axes.flat[1].set(xlabel='feature 1', ylabel='feature 2')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(f'{reducer_name}.jpg', dpi=1200)\n",
    "\n",
    "        for ax in axes:\n",
    "            ax.label_outer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/envs/umap_test/lib/python3.8/site-packages/sklearn/manifold/_spectral_embedding.py:236: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n"
     ]
    }
   ],
   "source": [
    "for reducer_name, X in reduced_datas.items():\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    fig, axes = plt.subplots(1, 2)\n",
    "    for i, model in enumerate([\n",
    "                  # MLPRegressor(max_iter=10,learning_rate_init=0.001, hidden_layer_sizes=(100, 500, 200)),\n",
    "                  LinearRegression(),\n",
    "                  # BayesianRidge(),\n",
    "                  # ElasticNet(),\n",
    "                  # GradientBoostingRegressor(),\n",
    "                  # ExtraTreesRegressor(),\n",
    "                  # RandomForestRegressor(),\n",
    "                  # BaggingRegressor(),\n",
    "                  # AdaBoostRegressor()\n",
    "                  ]):\n",
    "        model.fit(X_train, y_train)\n",
    "        print(f'{reducer_name} {model} MAE mean (cv=2) ={cross_val_score(model, X_test, y_test, scoring=\"neg_mean_absolute_error\", cv=2).mean()}')\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        fig.suptitle(f'Data after {reducer_name}')\n",
    "        axes[0].scatter(y_test, y_pred)\n",
    "        axes[0].set_title(f'{model}')\n",
    "        axes[0].set(xlabel='real price', ylabel='predicted price', xlim=0, ylim=0)\n",
    "\n",
    "        axes.flat[1].scatter(X[0], X[1])\n",
    "        axes.flat[1].set_title('features dependency')\n",
    "        axes.flat[1].set(xlabel='feature 1', ylabel='feature 2')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(f'{reducer_name}.jpg', dpi=1200)\n",
    "\n",
    "        for ax in axes:\n",
    "            ax.label_outer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for reducer_name, X in reduced_datas.items():\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    fig, axes = plt.subplots(1, 2)\n",
    "    for i, model in enumerate([\n",
    "                  # MLPRegressor(max_iter=10,learning_rate_init=0.001, hidden_layer_sizes=(100, 500, 200)),\n",
    "                  LinearRegression(),\n",
    "                  # BayesianRidge(),\n",
    "                  # ElasticNet(),\n",
    "                  # GradientBoostingRegressor(),\n",
    "                  # ExtraTreesRegressor(),\n",
    "                  # RandomForestRegressor(),\n",
    "                  # BaggingRegressor(),\n",
    "                  # AdaBoostRegressor()\n",
    "                  ]):\n",
    "        model.fit(X_train, y_train)\n",
    "        print(f'{reducer_name} {model} MAE mean (cv=2) ={cross_val_score(model, X_test, y_test, scoring=\"neg_mean_absolute_error\", cv=2).mean()}')\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        fig.suptitle(f'Data after {reducer_name}')\n",
    "        axes[0].scatter(y_test, y_pred)\n",
    "        axes[0].set_title(f'{model}')\n",
    "        axes[0].set(xlabel='real price', ylabel='predicted price', xlim=0, ylim=0)\n",
    "\n",
    "        axes.flat[1].scatter(X[0], X[1])\n",
    "        axes.flat[1].set_title('features dependency')\n",
    "        axes.flat[1].set(xlabel='feature 1', ylabel='feature 2')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        fig.savefig(f'{reducer_name}.jpg', dpi=1200)\n",
    "\n",
    "        for ax in axes:\n",
    "            ax.label_outer()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}